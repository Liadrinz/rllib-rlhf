# RLlib-RLHF

An RLlib implementation example of Reinforcement Learning from Human Feedback (RLHF)

## Project Structure

- `algo.py`: RLlib policy, algorithm customization
- `data_utils.py`: PyTorch dataset for prompt data
- `lm_env.py`: Environment for language modeling
- `model.py`: RLlib model customization
- `reward.py`: Reward model
- `train.py`: Training and evaluation using ray
